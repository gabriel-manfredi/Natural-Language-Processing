{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, fbeta_score, precision_score, recall_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from itertools import groupby\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 999\n",
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('twitts.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv('test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['keyword'].notnull(), 'text'] = train['text'] + '. ' + train['keyword']\n",
    "test.loc[test['keyword'].notnull(), 'text'] = test['text'] + '. ' + test['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "compiler = re.compile(\"[\\w'#:/.]+\")\n",
    "all_twitts=[]\n",
    "for twitt in train.text:\n",
    "    this_twitt=str()\n",
    "    for word in compiler.findall(twitt.lower()):\n",
    "        this_twitt+=word\n",
    "        this_twitt+=' '\n",
    "    all_twitts.append(this_twitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=all_twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_twitts=[]\n",
    "for twitt in test.text:\n",
    "    this_twitt=str()\n",
    "    for word in compiler.findall(twitt.lower()):\n",
    "        this_twitt+=word\n",
    "        this_twitt+=' '\n",
    "    all_twitts.append(this_twitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text']=all_twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# NLTK Tweet Tokenizer for now\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer(strip_handles=True)\n",
    "\n",
    "corpus = []\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\x89Û_\", \"\", text)\n",
    "    text = re.sub(r\"\\x89ÛÒ\", \"\", text)\n",
    "    text = re.sub(r\"\\x89ÛÓ\", \"\", text)\n",
    "    text = re.sub(r\"\\x89ÛÏWhen\", \"When\", text)\n",
    "    text = re.sub(r\"\\x89ÛÏ\", \"\", text)\n",
    "    text = re.sub(r\"China\\x89Ûªs\", \"China's\", text)\n",
    "    text = re.sub(r\"let\\x89Ûªs\", \"let's\", text)\n",
    "    text = re.sub(r\"\\x89Û÷\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ûª\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Û\\x9d\", \"\", text)\n",
    "    text = re.sub(r\"å_\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Û¢\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Û¢åÊ\", \"\", text)\n",
    "    text = re.sub(r\"fromåÊwounds\", \"from wounds\", text)\n",
    "    text = re.sub(r\"åÊ\", \"\", text)\n",
    "    text = re.sub(r\"åÈ\", \"\", text)\n",
    "    text = re.sub(r\"JapÌ_n\", \"Japan\", text)    \n",
    "    text = re.sub(r\"Ì©\", \"e\", text)\n",
    "    text = re.sub(r\"å¨\", \"\", text)\n",
    "    text = re.sub(r\"SuruÌ¤\", \"Suruc\", text)\n",
    "    text = re.sub(r\"åÇ\", \"\", text)\n",
    "    text = re.sub(r\"å£3million\", \"3 million\", text)\n",
    "    text = re.sub(r\"åÀ\", \"\", text)\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    for p in string.punctuation.replace('!', ''):\n",
    "        text = text.replace(p, '')\n",
    "        \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>3122</td>\n",
       "      <td>debris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mh debris found on reunion island sad tragedy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>1472</td>\n",
       "      <td>body%20bagging</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>imad i was going to tell him but you were body...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>7202</td>\n",
       "      <td>natural%20disaster</td>\n",
       "      <td>New York</td>\n",
       "      <td>rationing of food and water may also become ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>145</td>\n",
       "      <td>accident</td>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>i still have not heard church leaders of kenya...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>5647</td>\n",
       "      <td>flooding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>crabbycale oh my god the memories are flooding...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             keyword        location  \\\n",
       "2178  3122              debris             NaN   \n",
       "1013  1472      body%20bagging        Arizona    \n",
       "5053  7202  natural%20disaster        New York   \n",
       "101    145            accident  Nairobi, Kenya   \n",
       "3973  5647            flooding             NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "2178  mh debris found on reunion island sad tragedy ...       1  \n",
       "1013  imad i was going to tell him but you were body...       0  \n",
       "5053  rationing of food and water may also become ne...       0  \n",
       "101   i still have not heard church leaders of kenya...       0  \n",
       "3973  crabbycale oh my god the memories are flooding...       0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train['text'].apply(lambda s: clean_text(s))\n",
    "test['text'] = test['text'].apply(lambda s: clean_text(s))\n",
    "\n",
    "# see some cleaned data\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
    "train.loc[train['id'].isin(ids_with_target_error),'target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "compiler = re.compile(\"[\\w'#:/.]+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes the data suitable for input to FastText\n",
    "def create_file(x, y, fname):\n",
    "    with open(fname, 'w', encoding='utf-8') as f:\n",
    "        for i, x_i in enumerate(x):\n",
    "            if i > 0: f.write('\\n')\n",
    "            f.write(f'__label__{y[i]} {x_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    probs=[]\n",
    "    for labels, scores in zip(*model.predict(X, k=2)):\n",
    "        probs.append(dict(zip(labels, scores))['__label__1'])\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train['text'], train['target'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file(X_train, y_train.to_list(), 'train.data')\n",
    "create_file(X_test, y_test.to_list(), 'test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ftext = fasttext.train_supervised(input='train.data',  minCount=3, lr=0.1, wordNgrams=1, minn=9, maxn=9, dim=100, epoch=5, loss='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--CLASS 1--\n",
      "Training ROC-AUC:  0.92\n",
      "Testing ROC-AUC 0.85\n",
      "Training PR-AUC 0.91\n",
      "Testing PR-AUC 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "print('--CLASS 1--')\n",
    "print('Training ROC-AUC: ', round(roc_auc_score(y_train, predict(model_ftext, list(X_train))), 2))\n",
    "print('Testing ROC-AUC', round(roc_auc_score(y_test, predict(model_ftext, list(X_test))), 2))\n",
    "print('Training PR-AUC', round(average_precision_score(y_train, predict(model_ftext, list(X_train))),2))\n",
    "print('Testing PR-AUC', round(average_precision_score(y_test, predict(model_ftext, list(X_test))),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  79.88 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>true</th>\n",
       "      <th>proba</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so you have a new weapon that can cause un ima...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the f amp ing things i do for gishwhes just go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt georgegalloway rt gallowaymayor ûïthe col p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               twitt  true     proba  \\\n",
       "0  so you have a new weapon that can cause un ima...     1  0.023621   \n",
       "1  the f amp ing things i do for gishwhes just go...     0  0.141299   \n",
       "2  dt georgegalloway rt gallowaymayor ûïthe col p...     1  0.563596   \n",
       "\n",
       "   prediction  correct  \n",
       "0           0        0  \n",
       "1           0        1  \n",
       "2           1        1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see_preds = pd.DataFrame()\n",
    "see_preds['twitt'] = X_test\n",
    "see_preds['true'] = y_test\n",
    "see_preds['proba'] = predict(model_ftext, list(X_test))\n",
    "see_preds['prediction'] = see_preds['proba'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "see_preds['correct'] = [1 if x==y else 0 for x, y in zip(see_preds['prediction'], see_preds['true'])]\n",
    "print('Accuracy: ', round(see_preds.correct.mean()*100, 2), '%')\n",
    "see_preds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def evaluate_model(params):\n",
    "    model= fasttext.train_supervised(input='train.data', \n",
    "                                     minCount=params['minCount'], \n",
    "                                     lr=params['lr'], \n",
    "                                     wordNgrams=params['wordNgrams'], \n",
    "                                     minn=params['minn'], \n",
    "                                     maxn=params['maxn'], \n",
    "                                     dim=params['dim'], \n",
    "                                     epoch=params['epoch'], \n",
    "                                     loss=params['loss_func'])\n",
    "    \n",
    "    see_preds = pd.DataFrame()\n",
    "    see_preds['twitt'] = X_test\n",
    "    see_preds['true'] = y_test\n",
    "    see_preds['proba'] = predict(model, list(X_test))\n",
    "    see_preds['prediction'] = see_preds['proba'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "    see_preds['correct'] = [1 if x==y else 0 for x, y in zip(see_preds['prediction'], see_preds['true'])]\n",
    "    accuracy = round(see_preds.correct.mean()*100, 3)\n",
    "\n",
    "    return {\n",
    "        'minCount': params['minCount'],\n",
    "        'lr': params['lr'], \n",
    "        'wordNgrams': params['wordNgrams'], \n",
    "        'dim': params['dim'],\n",
    "        'epoch': params['epoch'],\n",
    "        'loss_func': params['loss_func'],\n",
    "        'minn': params['minn'],\n",
    "        'maxn': params['maxn'],\n",
    "        'Training ROC-AUC': round(roc_auc_score(y_train, predict(model, list(X_train))), 3),\n",
    "        'Testing ROC-AUC': round(roc_auc_score(y_test, predict(model, list(X_test))), 3),\n",
    "        'Training PR-AUC': round(average_precision_score(y_train, predict(model, list(X_train))),3),\n",
    "        'Testing PR-AUC': round(average_precision_score(y_test, predict(model, list(X_test))), 3),\n",
    "        'Testing ACCURACY': accuracy\n",
    "    }\n",
    "\n",
    "def objective(params):\n",
    "    res = evaluate_model(params)\n",
    "    \n",
    "    res['loss'] = - res['Testing ACCURACY']\n",
    "    res['status'] = STATUS_OK\n",
    "    return res \n",
    "\n",
    "hyperparameter_space = {\n",
    "        'minCount': hp.choice('minCount', range(1, 10)),\n",
    "        'lr': hp.uniform('lr',0.0001, 0.3),\n",
    "        'wordNgrams': hp.choice('wordNgrams', range(1, 4)),\n",
    "        'dim': hp.choice('dim', range(5, 300)),\n",
    "        'epoch': hp.choice('epoch', range(2, 25)),\n",
    "        'loss_func': hp.choice('loss_func', ['hs', 'softmax', 'ns']),\n",
    "        'minn': hp.choice('minn', range(2, 5)),\n",
    "        'maxn': hp.choice('maxn', range(4,8))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 100/100 [07:14<00:00,  4.35s/trial, best loss: -81.355]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "fmin(\n",
    "    objective,\n",
    "    space=hyperparameter_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trials\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minCount</th>\n",
       "      <th>lr</th>\n",
       "      <th>wordNgrams</th>\n",
       "      <th>dim</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>minn</th>\n",
       "      <th>maxn</th>\n",
       "      <th>Training ROC-AUC</th>\n",
       "      <th>Testing ROC-AUC</th>\n",
       "      <th>Training PR-AUC</th>\n",
       "      <th>Testing PR-AUC</th>\n",
       "      <th>Testing ACCURACY</th>\n",
       "      <th>loss</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>0.167603</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>11</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.858</td>\n",
       "      <td>81.355</td>\n",
       "      <td>-81.355</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6</td>\n",
       "      <td>0.186716</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>11</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.856</td>\n",
       "      <td>81.355</td>\n",
       "      <td>-81.355</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.159327</td>\n",
       "      <td>2</td>\n",
       "      <td>145</td>\n",
       "      <td>11</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.857</td>\n",
       "      <td>81.197</td>\n",
       "      <td>-81.197</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5</td>\n",
       "      <td>0.176593</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.859</td>\n",
       "      <td>81.145</td>\n",
       "      <td>-81.145</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9</td>\n",
       "      <td>0.142362</td>\n",
       "      <td>2</td>\n",
       "      <td>205</td>\n",
       "      <td>13</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.854</td>\n",
       "      <td>80.935</td>\n",
       "      <td>-80.935</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>0.252513</td>\n",
       "      <td>2</td>\n",
       "      <td>209</td>\n",
       "      <td>11</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.860</td>\n",
       "      <td>80.935</td>\n",
       "      <td>-80.935</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7</td>\n",
       "      <td>0.298277</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.858</td>\n",
       "      <td>80.882</td>\n",
       "      <td>-80.882</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    minCount        lr  wordNgrams  dim  epoch loss_func  minn  maxn  \\\n",
       "24         9  0.167603           2  214     11   softmax     4     5   \n",
       "74         6  0.186716           2  113     11   softmax     4     6   \n",
       "27         1  0.159327           2  145     11   softmax     4     5   \n",
       "67         5  0.176593           2   22     11   softmax     4     5   \n",
       "85         9  0.142362           2  205     13   softmax     4     6   \n",
       "37         5  0.252513           2  209     11   softmax     4     5   \n",
       "31         7  0.298277           2   20     10   softmax     4     7   \n",
       "\n",
       "    Training ROC-AUC  Testing ROC-AUC  Training PR-AUC  Testing PR-AUC  \\\n",
       "24             0.967            0.871            0.962           0.858   \n",
       "74             0.969            0.870            0.964           0.856   \n",
       "27             0.965            0.870            0.960           0.857   \n",
       "67             0.975            0.871            0.971           0.859   \n",
       "85             0.960            0.868            0.954           0.854   \n",
       "37             0.990            0.871            0.988           0.860   \n",
       "31             0.987            0.869            0.984           0.858   \n",
       "\n",
       "    Testing ACCURACY    loss status  \n",
       "24            81.355 -81.355     ok  \n",
       "74            81.355 -81.355     ok  \n",
       "27            81.197 -81.197     ok  \n",
       "67            81.145 -81.145     ok  \n",
       "85            80.935 -80.935     ok  \n",
       "37            80.935 -80.935     ok  \n",
       "31            80.882 -80.882     ok  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results = pd.DataFrame(trials.results)\n",
    "experiment_results.sort_values(by='loss').head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an accuracy of 81.3% and a ROC-AUC of 0.87 on the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
