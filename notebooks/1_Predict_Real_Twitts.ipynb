{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, fbeta_score, precision_score, recall_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm.notebook import tqdm\n",
    "import csv\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from itertools import groupby\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_columns = 999\n",
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv('test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['keyword'].notnull(), 'text'] = train['text'] + '. ' + train['keyword']\n",
    "test.loc[test['keyword'].notnull(), 'text'] = test['text'] + '. ' + test['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_twitts=[]\n",
    "for twitt in train.text:\n",
    "    this_twitt=str()\n",
    "    for word in compiler.findall(twitt.lower()):\n",
    "        this_twitt+=word\n",
    "        this_twitt+=' '\n",
    "    all_twitts.append(this_twitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']=all_twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_twitts=[]\n",
    "for twitt in test.text:\n",
    "    this_twitt=str()\n",
    "    for word in compiler.findall(twitt.lower()):\n",
    "        this_twitt+=word\n",
    "        this_twitt+=' '\n",
    "    all_twitts.append(this_twitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text']=all_twitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# NLTK Tweet Tokenizer for now\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer(strip_handles=True)\n",
    "\n",
    "corpus = []\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\x89Û_\", \"\", text)\n",
    "    text = re.sub(r\"\\x89ÛÒ\", \"\", text)\n",
    "    text = re.sub(r\"\\x89ÛÓ\", \"\", text)\n",
    "    text = re.sub(r\"\\x89ÛÏWhen\", \"When\", text)\n",
    "    text = re.sub(r\"\\x89ÛÏ\", \"\", text)\n",
    "    text = re.sub(r\"China\\x89Ûªs\", \"China's\", text)\n",
    "    text = re.sub(r\"let\\x89Ûªs\", \"let's\", text)\n",
    "    text = re.sub(r\"\\x89Û÷\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Ûª\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Û\\x9d\", \"\", text)\n",
    "    text = re.sub(r\"å_\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Û¢\", \"\", text)\n",
    "    text = re.sub(r\"\\x89Û¢åÊ\", \"\", text)\n",
    "    text = re.sub(r\"fromåÊwounds\", \"from wounds\", text)\n",
    "    text = re.sub(r\"åÊ\", \"\", text)\n",
    "    text = re.sub(r\"åÈ\", \"\", text)\n",
    "    text = re.sub(r\"JapÌ_n\", \"Japan\", text)    \n",
    "    text = re.sub(r\"Ì©\", \"e\", text)\n",
    "    text = re.sub(r\"å¨\", \"\", text)\n",
    "    text = re.sub(r\"SuruÌ¤\", \"Suruc\", text)\n",
    "    text = re.sub(r\"åÇ\", \"\", text)\n",
    "    text = re.sub(r\"å£3million\", \"3 million\", text)\n",
    "    text = re.sub(r\"åÀ\", \"\", text)\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    text = re.sub(r'[0-9]', '', text)\n",
    "    \n",
    "    for p in string.punctuation.replace('!', ''):\n",
    "        text = text.replace(p, '')\n",
    "        \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "   # text = [w.lower() for w in text if not w in stop_words]\n",
    "   # corpus.append(text)\n",
    "    \n",
    "  #  text = ' '.join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6675</th>\n",
       "      <td>9566</td>\n",
       "      <td>thunder</td>\n",
       "      <td>Decatur, GA</td>\n",
       "      <td>kristyleemusic brings her alabama thunder back...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>4575</td>\n",
       "      <td>emergency%20plan</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>bc it costs less to have sick people using eme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>1672</td>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>ameenshaikh by ur logic if bridge didnt collap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>9563</td>\n",
       "      <td>thunder</td>\n",
       "      <td>South Carolina, USA</td>\n",
       "      <td>the worst part is seeing lightning and trying ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458</th>\n",
       "      <td>7785</td>\n",
       "      <td>police</td>\n",
       "      <td>NaN</td>\n",
       "      <td>photo lastma officials challenge police for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            keyword             location  \\\n",
       "6675  9566            thunder          Decatur, GA   \n",
       "3186  4575   emergency%20plan          Atlanta, GA   \n",
       "1161  1672  bridge%20collapse               Mumbai   \n",
       "6672  9563            thunder  South Carolina, USA   \n",
       "5458  7785             police                  NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "6675  kristyleemusic brings her alabama thunder back...       0  \n",
       "3186  bc it costs less to have sick people using eme...       1  \n",
       "1161  ameenshaikh by ur logic if bridge didnt collap...       1  \n",
       "6672  the worst part is seeing lightning and trying ...       0  \n",
       "5458    photo lastma officials challenge police for ...       1  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train['text'].apply(lambda s: clean_text(s))\n",
    "test['text'] = test['text'].apply(lambda s: clean_text(s))\n",
    "\n",
    "# see some cleaned data\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
    "train.loc[train['id'].isin(ids_with_target_error),'target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "compiler = re.compile(\"[\\w'#:/.]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(x, y, fname):\n",
    "    with open(fname, 'w', encoding='utf-8') as f:\n",
    "        for i, x_i in enumerate(x):\n",
    "            if i > 0: f.write('\\n')\n",
    "            f.write(f'__label__{y[i]} {x_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    probs=[]\n",
    "    for labels, scores in zip(*model.predict(X, k=2)):\n",
    "        probs.append(dict(zip(labels, scores))['__label__1'])\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train['text'], train['target'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file(X_train, y_train.to_list(), 'train.data')\n",
    "create_file(X_test, y_test.to_list(), 'test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ftext = fasttext.train_supervised(input='train.data',  minCount=3, lr=0.1, wordNgrams=1, minn=9, maxn=9, dim=100, epoch=5, loss='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--CLASS 1--\n",
      "Training ROC-AUC:  0.94\n",
      "Testing ROC-AUC 0.86\n",
      "Training PR-AUC 0.93\n",
      "Testing PR-AUC 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "print('--CLASS 1--')\n",
    "print('Training ROC-AUC: ', round(roc_auc_score(y_train, predict(model_ftext, list(X_train))), 2))\n",
    "print('Testing ROC-AUC', round(roc_auc_score(y_test, predict(model_ftext, list(X_test))), 2))\n",
    "print('Training PR-AUC', round(average_precision_score(y_train, predict(model_ftext, list(X_train))),2))\n",
    "print('Testing PR-AUC', round(average_precision_score(y_test, predict(model_ftext, list(X_test))),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  80.83 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>twitt</th>\n",
       "      <th>true</th>\n",
       "      <th>proba</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so you have a new weapon that can cause un ima...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the f amp ing things i do for gishwhes just go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157940</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt georgegalloway rt gallowaymayor ûïthe col p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               twitt  true     proba  \\\n",
       "0  so you have a new weapon that can cause un ima...     1  0.016756   \n",
       "1  the f amp ing things i do for gishwhes just go...     0  0.157940   \n",
       "2  dt georgegalloway rt gallowaymayor ûïthe col p...     1  0.523016   \n",
       "\n",
       "   prediction  correct  \n",
       "0           0        0  \n",
       "1           0        1  \n",
       "2           1        1  "
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see_preds = pd.DataFrame()\n",
    "see_preds['twitt'] = X_test\n",
    "see_preds['true'] = y_test\n",
    "see_preds['proba'] = predict(model_ftext, list(X_test))\n",
    "see_preds['prediction'] = see_preds['proba'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "see_preds['correct'] = [1 if x==y else 0 for x, y in zip(see_preds['prediction'], see_preds['true'])]\n",
    "print('Accuracy: ', round(see_preds.correct.mean()*100, 2), '%')\n",
    "see_preds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "def evaluate_model(params):\n",
    "    model= fasttext.train_supervised(input='train.data', \n",
    "                                     minCount=params['minCount'], \n",
    "                                     lr=params['lr'], \n",
    "                                     wordNgrams=params['wordNgrams'], \n",
    "                                     minn=params['minn'], \n",
    "                                     maxn=params['maxn'], \n",
    "                                     dim=params['dim'], \n",
    "                                     epoch=params['epoch'], \n",
    "                                     loss=params['loss_func'])\n",
    "    \n",
    "    see_preds = pd.DataFrame()\n",
    "    see_preds['twitt'] = X_test\n",
    "    see_preds['true'] = y_test\n",
    "    see_preds['proba'] = predict(model, list(X_test))\n",
    "    see_preds['prediction'] = see_preds['proba'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "    see_preds['correct'] = [1 if x==y else 0 for x, y in zip(see_preds['prediction'], see_preds['true'])]\n",
    "    accuracy = round(see_preds.correct.mean()*100, 3)\n",
    "\n",
    "    return {\n",
    "        'minCount': params['minCount'],\n",
    "        'lr': params['lr'], \n",
    "        'wordNgrams': params['wordNgrams'], \n",
    "        'dim': params['dim'],\n",
    "        'epoch': params['epoch'],\n",
    "        'loss_func': params['loss_func'],\n",
    "        'minn': params['minn'],\n",
    "        'maxn': params['maxn'],\n",
    "        'Training ROC-AUC': round(roc_auc_score(y_train, predict(model, list(X_train))), 3),\n",
    "        'Testing ROC-AUC': round(roc_auc_score(y_test, predict(model, list(X_test))), 3),\n",
    "        'Training PR-AUC': round(average_precision_score(y_train, predict(model, list(X_train))),3),\n",
    "        'Testing PR-AUC': round(average_precision_score(y_test, predict(model, list(X_test))), 3),\n",
    "        'Testing ACCURACY': accuracy\n",
    "    }\n",
    "\n",
    "def objective(params):\n",
    "    res = evaluate_model(params)\n",
    "    \n",
    "    res['loss'] = - res['Testing ACCURACY'] # Esta loss es la que hyperopt intenta minimizar\n",
    "    res['status'] = STATUS_OK # Asi le decimos a hyperopt que el experimento salio bien\n",
    "    return res \n",
    "\n",
    "# Este espacio es una copia del grid search, no estamos dando mucha información en este prior\n",
    "hyperparameter_space = {\n",
    "        'minCount': hp.choice('minCount', range(1, 10)),\n",
    "        'lr': hp.uniform('lr',0.0001, 0.3),\n",
    "        'wordNgrams': hp.choice('wordNgrams', range(1, 4)),\n",
    "        'dim': hp.choice('dim', range(5, 300)),\n",
    "        'epoch': hp.choice('epoch', range(2, 25)),\n",
    "        'loss_func': hp.choice('loss_func', ['hs', 'softmax', 'ns']),\n",
    "        'minn': hp.choice('minn', range(2, 5)),\n",
    "        'maxn': hp.choice('maxn', range(4,8))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 200/200 [13:43<00:00,  4.12s/trial, best loss: -81.723]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "fmin(\n",
    "    objective,\n",
    "    space=hyperparameter_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=200,\n",
    "    trials=trials\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minCount</th>\n",
       "      <th>lr</th>\n",
       "      <th>wordNgrams</th>\n",
       "      <th>dim</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>minn</th>\n",
       "      <th>maxn</th>\n",
       "      <th>Training ROC-AUC</th>\n",
       "      <th>Testing ROC-AUC</th>\n",
       "      <th>Training PR-AUC</th>\n",
       "      <th>Testing PR-AUC</th>\n",
       "      <th>Testing ACCURACY</th>\n",
       "      <th>loss</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>2</td>\n",
       "      <td>213</td>\n",
       "      <td>10</td>\n",
       "      <td>ns</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.487</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>11</td>\n",
       "      <td>ns</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.519</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.546</td>\n",
       "      <td>61.870</td>\n",
       "      <td>-61.870</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8</td>\n",
       "      <td>0.075374</td>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "      <td>ns</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.550</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>0.019106</td>\n",
       "      <td>1</td>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.603</td>\n",
       "      <td>45.116</td>\n",
       "      <td>-45.116</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>7</td>\n",
       "      <td>0.026422</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.630</td>\n",
       "      <td>57.511</td>\n",
       "      <td>-57.511</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>20</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.624</td>\n",
       "      <td>51.155</td>\n",
       "      <td>-51.155</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2</td>\n",
       "      <td>0.045648</td>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>2</td>\n",
       "      <td>softmax</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.647</td>\n",
       "      <td>66.912</td>\n",
       "      <td>-66.912</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.028704</td>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>8</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.666</td>\n",
       "      <td>57.773</td>\n",
       "      <td>-57.773</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.026176</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>16</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.671</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>7</td>\n",
       "      <td>0.110832</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.691</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4</td>\n",
       "      <td>0.084528</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>ns</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.664</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>0.295944</td>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "      <td>2</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.711</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>0.180304</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.709</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>4</td>\n",
       "      <td>0.108109</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>4</td>\n",
       "      <td>ns</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.664</td>\n",
       "      <td>57.458</td>\n",
       "      <td>-57.458</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8</td>\n",
       "      <td>0.036369</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.705</td>\n",
       "      <td>66.754</td>\n",
       "      <td>-66.754</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>7</td>\n",
       "      <td>0.069464</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>softmax</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.748</td>\n",
       "      <td>58.351</td>\n",
       "      <td>-58.351</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>0.217743</td>\n",
       "      <td>2</td>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "      <td>hs</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.775</td>\n",
       "      <td>61.029</td>\n",
       "      <td>-61.029</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>0.221902</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>4</td>\n",
       "      <td>hs</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.775</td>\n",
       "      <td>60.819</td>\n",
       "      <td>-60.819</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.199659</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>softmax</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.777</td>\n",
       "      <td>62.237</td>\n",
       "      <td>-62.237</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>9</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.783</td>\n",
       "      <td>65.704</td>\n",
       "      <td>-65.704</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8</td>\n",
       "      <td>0.115534</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.794</td>\n",
       "      <td>61.187</td>\n",
       "      <td>-61.187</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>0.137165</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>7</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.772</td>\n",
       "      <td>64.128</td>\n",
       "      <td>-64.128</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.145490</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.783</td>\n",
       "      <td>67.857</td>\n",
       "      <td>-67.857</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4</td>\n",
       "      <td>0.016657</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>18</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.794</td>\n",
       "      <td>62.553</td>\n",
       "      <td>-62.553</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>0.038551</td>\n",
       "      <td>2</td>\n",
       "      <td>224</td>\n",
       "      <td>8</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.779</td>\n",
       "      <td>72.164</td>\n",
       "      <td>-72.164</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>8</td>\n",
       "      <td>0.053387</td>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>11</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.799</td>\n",
       "      <td>65.966</td>\n",
       "      <td>-65.966</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>4</td>\n",
       "      <td>0.046871</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>9</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.805</td>\n",
       "      <td>63.445</td>\n",
       "      <td>-63.445</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7</td>\n",
       "      <td>0.193323</td>\n",
       "      <td>3</td>\n",
       "      <td>205</td>\n",
       "      <td>3</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.798</td>\n",
       "      <td>67.122</td>\n",
       "      <td>-67.122</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4</td>\n",
       "      <td>0.192515</td>\n",
       "      <td>3</td>\n",
       "      <td>220</td>\n",
       "      <td>3</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.802</td>\n",
       "      <td>66.912</td>\n",
       "      <td>-66.912</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>0.299783</td>\n",
       "      <td>3</td>\n",
       "      <td>278</td>\n",
       "      <td>2</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.800</td>\n",
       "      <td>67.805</td>\n",
       "      <td>-67.805</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>4</td>\n",
       "      <td>0.189850</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.818</td>\n",
       "      <td>69.538</td>\n",
       "      <td>-69.538</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.163804</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.815</td>\n",
       "      <td>74.632</td>\n",
       "      <td>-74.632</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0.079472</td>\n",
       "      <td>2</td>\n",
       "      <td>268</td>\n",
       "      <td>13</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.816</td>\n",
       "      <td>74.475</td>\n",
       "      <td>-74.475</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6</td>\n",
       "      <td>0.139287</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>9</td>\n",
       "      <td>hs</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.812</td>\n",
       "      <td>76.943</td>\n",
       "      <td>-76.943</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>8</td>\n",
       "      <td>0.029288</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.824</td>\n",
       "      <td>75.473</td>\n",
       "      <td>-75.473</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2</td>\n",
       "      <td>0.174002</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>8</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.805</td>\n",
       "      <td>78.046</td>\n",
       "      <td>-78.046</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>4</td>\n",
       "      <td>0.138569</td>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>4</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.824</td>\n",
       "      <td>75.893</td>\n",
       "      <td>-75.893</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>0.114506</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>11</td>\n",
       "      <td>hs</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.813</td>\n",
       "      <td>78.519</td>\n",
       "      <td>-78.519</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>4</td>\n",
       "      <td>0.068393</td>\n",
       "      <td>3</td>\n",
       "      <td>294</td>\n",
       "      <td>9</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.827</td>\n",
       "      <td>79.202</td>\n",
       "      <td>-79.202</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>0.086665</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18</td>\n",
       "      <td>hs</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.813</td>\n",
       "      <td>78.204</td>\n",
       "      <td>-78.204</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2</td>\n",
       "      <td>0.089393</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>softmax</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.826</td>\n",
       "      <td>79.779</td>\n",
       "      <td>-79.779</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>4</td>\n",
       "      <td>0.105563</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.831</td>\n",
       "      <td>80.147</td>\n",
       "      <td>-80.147</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.229457</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>hs</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.829</td>\n",
       "      <td>80.305</td>\n",
       "      <td>-80.305</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9</td>\n",
       "      <td>0.079005</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>softmax</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.832</td>\n",
       "      <td>80.620</td>\n",
       "      <td>-80.620</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     minCount        lr  wordNgrams  dim  epoch loss_func  minn  maxn  \\\n",
       "1           2  0.014809           2  213     10        ns     2     7   \n",
       "40          6  0.006710           2  175     11        ns     4     4   \n",
       "173         5  0.009138           3   54      3   softmax     2     4   \n",
       "44          8  0.075374           2  142      4        ns     4     7   \n",
       "45          4  0.019106           1  257      2   softmax     2     4   \n",
       "194         7  0.026422           1   78      5   softmax     2     5   \n",
       "32          4  0.004146           2  122     20        hs     4     5   \n",
       "168         2  0.045648           3  157      2   softmax     3     4   \n",
       "3           8  0.028704           3  246      8        hs     2     7   \n",
       "6           6  0.026176           1   74     16        hs     2     7   \n",
       "133         7  0.110832           2  250      5        hs     2     6   \n",
       "195         4  0.084528           3   64      3        ns     4     4   \n",
       "80          4  0.295944           2  226      2        hs     2     4   \n",
       "18          5  0.180304           1   29      3        hs     2     5   \n",
       "102         4  0.108109           2  102      4        ns     2     6   \n",
       "37          8  0.036369           2   61      6        hs     4     5   \n",
       "167         7  0.069464           3   58      7   softmax     2     4   \n",
       "128         1  0.217743           2  255      4        hs     3     6   \n",
       "75          7  0.221902           2  166      4        hs     3     7   \n",
       "2           3  0.199659           1  178      3   softmax     3     7   \n",
       "131         9  0.238900           1   18      2        hs     4     6   \n",
       "188         8  0.115534           3   99      2   softmax     4     4   \n",
       "48          1  0.137165           1  144      7        hs     2     7   \n",
       "12          7  0.145490           3   66      2   softmax     4     7   \n",
       "164         4  0.016657           3   41     18   softmax     4     4   \n",
       "46          3  0.038551           2  224      8        hs     4     6   \n",
       "33          8  0.053387           2   97     11        hs     4     6   \n",
       "153         4  0.046871           3  234      9   softmax     4     4   \n",
       "51          7  0.193323           3  205      3        hs     4     6   \n",
       "112         4  0.192515           3  220      3        hs     4     6   \n",
       "101         2  0.299783           3  278      2        hs     4     7   \n",
       "135         4  0.189850           3   15      3        hs     4     4   \n",
       "10          3  0.163804           1   52      4   softmax     4     7   \n",
       "35          1  0.079472           2  268     13        hs     4     6   \n",
       "103         6  0.139287           2  126      9        hs     3     7   \n",
       "162         8  0.029288           3   51     17   softmax     4     4   \n",
       "91          2  0.174002           2  242      8        hs     2     6   \n",
       "166         4  0.138569           3  182      4   softmax     4     4   \n",
       "52          3  0.114506           1  207     11        hs     3     7   \n",
       "157         4  0.068393           3  294      9   softmax     4     4   \n",
       "127         3  0.086665           3  222     18        hs     2     6   \n",
       "181         2  0.089393           3   76      9   softmax     3     4   \n",
       "176         4  0.105563           3  168      6   softmax     4     4   \n",
       "27          1  0.229457           2   68      5        hs     4     6   \n",
       "191         9  0.079005           3   22      7   softmax     4     4   \n",
       "\n",
       "     Training ROC-AUC  Testing ROC-AUC  Training PR-AUC  Testing PR-AUC  \\\n",
       "1               0.598            0.604            0.487           0.487   \n",
       "40              0.611            0.625            0.506           0.519   \n",
       "173             0.632            0.636            0.538           0.546   \n",
       "44              0.684            0.661            0.576           0.550   \n",
       "45              0.692            0.698            0.598           0.603   \n",
       "194             0.706            0.708            0.623           0.630   \n",
       "32              0.718            0.700            0.650           0.624   \n",
       "168             0.727            0.713            0.663           0.647   \n",
       "3               0.745            0.737            0.683           0.666   \n",
       "6               0.746            0.738            0.693           0.671   \n",
       "133             0.753            0.747            0.703           0.691   \n",
       "195             0.760            0.736            0.700           0.664   \n",
       "80              0.764            0.761            0.718           0.711   \n",
       "18              0.764            0.760            0.718           0.709   \n",
       "102             0.771            0.740            0.697           0.664   \n",
       "37              0.776            0.763            0.731           0.705   \n",
       "167             0.799            0.790            0.763           0.748   \n",
       "128             0.811            0.804            0.790           0.775   \n",
       "75              0.811            0.802            0.791           0.775   \n",
       "2               0.814            0.806            0.793           0.777   \n",
       "131             0.817            0.806            0.792           0.783   \n",
       "188             0.819            0.808            0.801           0.794   \n",
       "48              0.821            0.810            0.792           0.772   \n",
       "12              0.822            0.810            0.794           0.783   \n",
       "164             0.823            0.812            0.805           0.794   \n",
       "46              0.824            0.806            0.799           0.779   \n",
       "33              0.832            0.819            0.815           0.799   \n",
       "153             0.832            0.820            0.817           0.805   \n",
       "51              0.834            0.820            0.819           0.798   \n",
       "112             0.835            0.822            0.820           0.802   \n",
       "101             0.837            0.821            0.821           0.800   \n",
       "135             0.852            0.835            0.837           0.818   \n",
       "10              0.860            0.840            0.844           0.815   \n",
       "35              0.861            0.841            0.845           0.816   \n",
       "103             0.863            0.843            0.845           0.812   \n",
       "162             0.865            0.844            0.851           0.824   \n",
       "91              0.866            0.836            0.849           0.805   \n",
       "166             0.867            0.844            0.853           0.824   \n",
       "52              0.867            0.845            0.850           0.813   \n",
       "157             0.876            0.848            0.863           0.827   \n",
       "127             0.878            0.840            0.865           0.813   \n",
       "181             0.882            0.847            0.872           0.826   \n",
       "176             0.884            0.851            0.873           0.831   \n",
       "27              0.886            0.853            0.873           0.829   \n",
       "191             0.886            0.851            0.876           0.832   \n",
       "\n",
       "     Testing ACCURACY    loss status  \n",
       "1              57.458 -57.458     ok  \n",
       "40             57.458 -57.458     ok  \n",
       "173            61.870 -61.870     ok  \n",
       "44             57.458 -57.458     ok  \n",
       "45             45.116 -45.116     ok  \n",
       "194            57.511 -57.511     ok  \n",
       "32             51.155 -51.155     ok  \n",
       "168            66.912 -66.912     ok  \n",
       "3              57.773 -57.773     ok  \n",
       "6              57.458 -57.458     ok  \n",
       "133            57.458 -57.458     ok  \n",
       "195            57.458 -57.458     ok  \n",
       "80             57.458 -57.458     ok  \n",
       "18             57.458 -57.458     ok  \n",
       "102            57.458 -57.458     ok  \n",
       "37             66.754 -66.754     ok  \n",
       "167            58.351 -58.351     ok  \n",
       "128            61.029 -61.029     ok  \n",
       "75             60.819 -60.819     ok  \n",
       "2              62.237 -62.237     ok  \n",
       "131            65.704 -65.704     ok  \n",
       "188            61.187 -61.187     ok  \n",
       "48             64.128 -64.128     ok  \n",
       "12             67.857 -67.857     ok  \n",
       "164            62.553 -62.553     ok  \n",
       "46             72.164 -72.164     ok  \n",
       "33             65.966 -65.966     ok  \n",
       "153            63.445 -63.445     ok  \n",
       "51             67.122 -67.122     ok  \n",
       "112            66.912 -66.912     ok  \n",
       "101            67.805 -67.805     ok  \n",
       "135            69.538 -69.538     ok  \n",
       "10             74.632 -74.632     ok  \n",
       "35             74.475 -74.475     ok  \n",
       "103            76.943 -76.943     ok  \n",
       "162            75.473 -75.473     ok  \n",
       "91             78.046 -78.046     ok  \n",
       "166            75.893 -75.893     ok  \n",
       "52             78.519 -78.519     ok  \n",
       "157            79.202 -79.202     ok  \n",
       "127            78.204 -78.204     ok  \n",
       "181            79.779 -79.779     ok  \n",
       "176            80.147 -80.147     ok  \n",
       "27             80.305 -80.305     ok  \n",
       "191            80.620 -80.620     ok  "
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results = pd.DataFrame(trials.results)\n",
    "experiment_results.sort_values(by='Training ROC-AUC').head(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with all data with those hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_file(train['text'], train['target'].to_list(), 'final_train.data')\n",
    "#create_file(X_test, y_test.to_list(), 'test.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ftext = fasttext.train_supervised(input='final_train.data',  minCount=1, lr=0.229457, wordNgrams=2, minn=4, maxn=6, dim=68, epoch=5, loss='hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--CLASS 1--\n",
      "Training ROC-AUC:  0.91\n",
      "Training PR-AUC 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "print('--CLASS 1--')\n",
    "print('Training ROC-AUC: ', round(roc_auc_score(train['target'].to_list(), predict(model_ftext, list(train['text']))), 2))\n",
    "print('Training PR-AUC', round(average_precision_score(train['target'].to_list(), predict(model_ftext, list(train['text']))),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model_ftext, list(test['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission['preds'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = submission['preds'].apply(lambda x: 1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.drop('preds', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
